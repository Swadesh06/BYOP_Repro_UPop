{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install transformers","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torchvision import datasets, transforms\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torchvision\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom tqdm import tqdm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((224, 224)),  # Resize CIFAR-10 images to 224x224 to match DeiT input size\n    transforms.ToTensor(),\n    # Normalize using ImageNet mean and std\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# Download and load CIFAR-10 training dataset\ntrain_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n\n# Download and load CIFAR-10 test dataset\ntest_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import DeiTForImageClassificationWithTeacher\n\nbaseline_model = DeiTForImageClassificationWithTeacher.from_pretrained('facebook/deit-base-distilled-patch16-224')\nbaseline_model = baseline_model.to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"baseline_model.distillation_classifier = torch.nn.Linear(in_features=baseline_model.distillation_classifier.in_features, out_features=10)\nbaseline_model.cls_classifier = torch.nn.Linear(in_features=baseline_model.cls_classifier.in_features, out_features=10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# After modifying the model's layers, ensure they are on the correct device\nbaseline_model.distillation_classifier.to(device)\nbaseline_model.cls_classifier.to(device)\n\n# Before starting the training loop, you can add a check like this\nfor name, param in baseline_model.named_parameters():\n    print(f\"{name} is on {param.device}\")\n\n# Ensure inputs are on the correct device right before the forward pass\ninputs, targets = inputs.to(device), targets.to(device)\n\n# Then proceed with your training loop\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import DeiTForImageClassificationWithTeacher\nimport torch.nn.functional as F\n\ndef train_one_epoch(epoch, model, train_loader, optimizer, device):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    \n    progress_bar = tqdm(enumerate(train_loader), total=len(train_loader))\n    for batch_idx, (inputs, targets) in progress_bar:\n        inputs, targets = inputs.to(device), targets.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = F.cross_entropy(outputs.logits, targets)  # Corrected to use outputs.logits\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        _, predicted = outputs.logits.max(1)\n        total += targets.size(0)\n        correct += predicted.eq(targets).sum().item()\n\n        progress_bar.set_description(f'Epoch {epoch} Loss: {running_loss/(batch_idx+1):.3f} Acc: {100.*correct/total:.3f}%')\n    \n    return running_loss / len(train_loader), 100.*correct / total\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def validate(model, test_loader, device):\n    model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for inputs, targets in test_loader:\n            inputs, targets = inputs.to(device), targets.to(device)\n            outputs = model(inputs)\n            _, predicted = outputs.logits.max(1)\n            total += targets.size(0)\n            correct += predicted.eq(targets).sum().item()\n    \n    acc = 100.*correct / total\n    print(f'Validation Accuracy: {acc:.3f}%')\n    return acc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = optim.Adam(baseline_model.parameters(), lr=0.001)\nmax_epoch = 16","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(1,17):\n    print(f\"Epoch {epoch}: Normal Training\")\n    train_loss, train_acc = train_one_epoch(epoch, baseline_model, train_loader, optimizer, device)\n    print(f\"Training Loss: {train_loss}, Training Accuracy: {train_acc}\")\n    val_acc = validate(baseline_model, test_loader, device)\n    print(f\"Validation Accuracy: {val_acc}%\")\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}