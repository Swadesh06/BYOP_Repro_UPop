{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-09T11:34:51.162291Z","iopub.execute_input":"2024-02-09T11:34:51.163297Z","iopub.status.idle":"2024-02-09T11:34:51.171378Z","shell.execute_reply.started":"2024-02-09T11:34:51.163254Z","shell.execute_reply":"2024-02-09T11:34:51.170145Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom transformers import DeiTForImageClassificationWithTeacher\nimport torchvision\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-02-09T11:34:51.173629Z","iopub.execute_input":"2024-02-09T11:34:51.173999Z","iopub.status.idle":"2024-02-09T11:34:51.189152Z","shell.execute_reply.started":"2024-02-09T11:34:51.173973Z","shell.execute_reply":"2024-02-09T11:34:51.188148Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def check_pruning_correctness_and_extent(model, compression_ratio):\n    print(\"Checking pruning correctness and extent...\")\n    for name, module in model.named_modules():\n        if isinstance(module, torch.nn.Linear):\n            # Calculate sparsity\n            total_weights = module.weight.numel()\n            zero_weights = total_weights - module.weight.data.nonzero().size(0)\n            sparsity = zero_weights / total_weights\n            expected_sparsity = compression_ratio\n            print(f\"{name}: Sparsity: {sparsity:.2f}. Expected: {expected_sparsity}.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-02-09T11:34:51.190454Z","iopub.execute_input":"2024-02-09T11:34:51.190773Z","iopub.status.idle":"2024-02-09T11:34:51.203058Z","shell.execute_reply.started":"2024-02-09T11:34:51.190746Z","shell.execute_reply":"2024-02-09T11:34:51.201779Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def freeze_pruned_weights(model):\n    for name, module in model.named_modules():\n        if isinstance(module, torch.nn.Linear):\n            mask = module.weight.data != 0  # A mask of which weights are non-zero\n            module.weight.register_hook(lambda grad, mask=mask: grad * mask)\n    print(\"Pruned weights are now frozen and will not be updated during training.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-02-09T11:34:51.204522Z","iopub.execute_input":"2024-02-09T11:34:51.205244Z","iopub.status.idle":"2024-02-09T11:34:51.215678Z","shell.execute_reply.started":"2024-02-09T11:34:51.205215Z","shell.execute_reply":"2024-02-09T11:34:51.214673Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-02-09T11:34:51.218459Z","iopub.execute_input":"2024-02-09T11:34:51.218886Z","iopub.status.idle":"2024-02-09T11:34:51.230743Z","shell.execute_reply.started":"2024-02-09T11:34:51.218847Z","shell.execute_reply":"2024-02-09T11:34:51.229654Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# Data preprocessing\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])","metadata":{"execution":{"iopub.status.busy":"2024-02-09T11:34:51.232167Z","iopub.execute_input":"2024-02-09T11:34:51.232618Z","iopub.status.idle":"2024-02-09T11:34:51.241764Z","shell.execute_reply.started":"2024-02-09T11:34:51.232579Z","shell.execute_reply":"2024-02-09T11:34:51.240765Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# Load CIFAR-10 dataset\ntrain_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\ntest_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T11:34:51.242968Z","iopub.execute_input":"2024-02-09T11:34:51.243310Z","iopub.status.idle":"2024-02-09T11:34:52.898395Z","shell.execute_reply.started":"2024-02-09T11:34:51.243284Z","shell.execute_reply":"2024-02-09T11:34:52.897448Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Files already downloaded and verified\nFiles already downloaded and verified\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load DeiT model\nmodel = DeiTForImageClassificationWithTeacher.from_pretrained('facebook/deit-base-distilled-patch16-224')\nmodel = model.to(device)\n\n# Adjust classifier for CIFAR-10 classes\nmodel.distillation_classifier = torch.nn.Linear(in_features=model.distillation_classifier.in_features, out_features=10)\nmodel.cls_classifier = torch.nn.Linear(in_features=model.cls_classifier.in_features, out_features=10)\nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T11:34:52.899568Z","iopub.execute_input":"2024-02-09T11:34:52.899876Z","iopub.status.idle":"2024-02-09T11:34:53.408056Z","shell.execute_reply.started":"2024-02-09T11:34:52.899851Z","shell.execute_reply":"2024-02-09T11:34:53.407166Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def apply_pruning_to_layer(layer, compression_ratio):\n    total_weights = layer.weight.numel()\n    num_weights_to_keep = int(total_weights * (1 - compression_ratio))\n    weights_abs = torch.abs(layer.weight.data.view(-1))\n    threshold = torch.kthvalue(weights_abs, num_weights_to_keep).values\n    mask = torch.ge(weights_abs, threshold).float().view(layer.weight.shape)\n    layer.weight.data.mul_(mask)\n    # Removed bias pruning to avoid the shape mismatch error","metadata":{"execution":{"iopub.status.busy":"2024-02-09T11:34:53.409223Z","iopub.execute_input":"2024-02-09T11:34:53.409547Z","iopub.status.idle":"2024-02-09T11:34:53.416076Z","shell.execute_reply.started":"2024-02-09T11:34:53.409521Z","shell.execute_reply":"2024-02-09T11:34:53.415069Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"def prune_model(model, compression_ratio):\n    with torch.no_grad():\n        for name, module in model.named_modules():\n            if isinstance(module, torch.nn.Linear):\n                apply_pruning_to_layer(module, compression_ratio)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T11:34:53.417669Z","iopub.execute_input":"2024-02-09T11:34:53.417989Z","iopub.status.idle":"2024-02-09T11:34:53.426712Z","shell.execute_reply.started":"2024-02-09T11:34:53.417963Z","shell.execute_reply":"2024-02-09T11:34:53.425795Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# def prune_model(model, compression_ratio):\n#     with torch.no_grad():\n#         for name, module in model.named_modules():\n#             if isinstance(module, torch.nn.Linear):\n#                 apply_pruning_to_layer(module, compression_ratio)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T11:34:53.430108Z","iopub.execute_input":"2024-02-09T11:34:53.430497Z","iopub.status.idle":"2024-02-09T11:34:53.440924Z","shell.execute_reply.started":"2024-02-09T11:34:53.430472Z","shell.execute_reply":"2024-02-09T11:34:53.440047Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"def train(model, train_loader, optimizer, epochs):\n    model.train()\n    for epoch in range(epochs):\n        total_loss = 0\n        progress_bar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f'Epoch {epoch+1}/{epochs}')\n        for batch_idx, (data, target) in progress_bar:\n            data, target = data.to(device), target.to(device)\n            optimizer.zero_grad()\n            output = model(data)\n            loss = F.cross_entropy(output.logits, target)\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n            progress_bar.set_postfix(loss=total_loss/(batch_idx+1))","metadata":{"execution":{"iopub.status.busy":"2024-02-09T11:34:53.442167Z","iopub.execute_input":"2024-02-09T11:34:53.442531Z","iopub.status.idle":"2024-02-09T11:34:53.454025Z","shell.execute_reply.started":"2024-02-09T11:34:53.442503Z","shell.execute_reply":"2024-02-09T11:34:53.452946Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"def test(model, test_loader):\n    model.eval()\n    correct = 0\n    total = 0\n    progress_bar = tqdm(enumerate(test_loader), total=len(test_loader), desc='Testing')\n    with torch.no_grad():\n        for batch_idx, (data, target) in progress_bar:\n            data, target = data.to(device), target.to(device)\n            output = model(data)\n            pred = output.logits.argmax(dim=1, keepdim=True)\n            correct += pred.eq(target.view_as(pred)).sum().item()\n            total += target.size(0)\n            progress_bar.set_postfix(acc=f'{100. * correct / total:.2f}%')\n\n    print(f'Test set: Accuracy: {correct}/{len(test_loader.dataset)} ({100. * correct / len(test_loader.dataset):.0f}%)')","metadata":{"execution":{"iopub.status.busy":"2024-02-09T11:34:53.455252Z","iopub.execute_input":"2024-02-09T11:34:53.455605Z","iopub.status.idle":"2024-02-09T11:34:53.464363Z","shell.execute_reply.started":"2024-02-09T11:34:53.455580Z","shell.execute_reply":"2024-02-09T11:34:53.463512Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# Parameters\ncompression_ratio = 0.5  # Example: 50% pruning\nepochs = 16  # Retraining epochs\n\n# Retrain the pruned model\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# Prune the model without causing shape mismatch errors\nprune_model(model, compression_ratio)\n\n# Check pruning correctness and extent\ncheck_pruning_correctness_and_extent(model, compression_ratio)\n\n# Freeze pruned weights\nfreeze_pruned_weights(model)\n\n# Retrain the pruned model\ntrain(model, train_loader, optimizer, epochs)\n\n# Evaluate the pruned and retrained model\ntest(model, test_loader)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-02-09T11:35:44.221479Z","iopub.execute_input":"2024-02-09T11:35:44.221901Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Checking pruning correctness and extent...\ndeit.encoder.layer.0.attention.attention.query: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.0.attention.attention.key: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.0.attention.attention.value: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.0.attention.output.dense: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.0.intermediate.dense: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.0.output.dense: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.1.attention.attention.query: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.1.attention.attention.key: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.1.attention.attention.value: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.1.attention.output.dense: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.1.intermediate.dense: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.1.output.dense: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.2.attention.attention.query: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.2.attention.attention.key: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.2.attention.attention.value: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.2.attention.output.dense: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.2.intermediate.dense: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.2.output.dense: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.3.attention.attention.query: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.3.attention.attention.key: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.3.attention.attention.value: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.3.attention.output.dense: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.3.intermediate.dense: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.3.output.dense: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.4.attention.attention.query: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.4.attention.attention.key: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.4.attention.attention.value: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.4.attention.output.dense: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.4.intermediate.dense: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.4.output.dense: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.5.attention.attention.query: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.5.attention.attention.key: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.5.attention.attention.value: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.5.attention.output.dense: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.5.intermediate.dense: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.5.output.dense: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.6.attention.attention.query: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.6.attention.attention.key: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.6.attention.attention.value: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.6.attention.output.dense: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.6.intermediate.dense: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.6.output.dense: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.7.attention.attention.query: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.7.attention.attention.key: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.7.attention.attention.value: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.7.attention.output.dense: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.7.intermediate.dense: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.7.output.dense: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.8.attention.attention.query: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.8.attention.attention.key: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.8.attention.attention.value: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.8.attention.output.dense: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.8.intermediate.dense: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.8.output.dense: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.9.attention.attention.query: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.9.attention.attention.key: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.9.attention.attention.value: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.9.attention.output.dense: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.9.intermediate.dense: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.9.output.dense: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.10.attention.attention.query: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.10.attention.attention.key: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.10.attention.attention.value: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.10.attention.output.dense: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.10.intermediate.dense: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.10.output.dense: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.11.attention.attention.query: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.11.attention.attention.key: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.11.attention.attention.value: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.11.attention.output.dense: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.11.intermediate.dense: Sparsity: 0.50. Expected: 0.5.\ndeit.encoder.layer.11.output.dense: Sparsity: 0.50. Expected: 0.5.\ncls_classifier: Sparsity: 0.50. Expected: 0.5.\ndistillation_classifier: Sparsity: 0.50. Expected: 0.5.\nPruned weights are now frozen and will not be updated during training.\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/16: 100%|██████████| 1563/1563 [15:20<00:00,  1.70it/s, loss=1.43]\nEpoch 2/16: 100%|██████████| 1563/1563 [15:20<00:00,  1.70it/s, loss=0.958]\nEpoch 3/16: 100%|██████████| 1563/1563 [15:19<00:00,  1.70it/s, loss=0.769]\nEpoch 4/16: 100%|██████████| 1563/1563 [15:20<00:00,  1.70it/s, loss=0.646]\nEpoch 5/16: 100%|██████████| 1563/1563 [15:20<00:00,  1.70it/s, loss=0.781]\nEpoch 6/16: 100%|██████████| 1563/1563 [15:20<00:00,  1.70it/s, loss=0.531]\nEpoch 7/16: 100%|██████████| 1563/1563 [15:21<00:00,  1.70it/s, loss=0.449]\nEpoch 8/16: 100%|██████████| 1563/1563 [15:21<00:00,  1.70it/s, loss=0.389]\nEpoch 9/16: 100%|██████████| 1563/1563 [15:20<00:00,  1.70it/s, loss=0.339]\nEpoch 10/16: 100%|██████████| 1563/1563 [15:20<00:00,  1.70it/s, loss=0.284]\nEpoch 11/16: 100%|██████████| 1563/1563 [15:19<00:00,  1.70it/s, loss=0.246]\nEpoch 12/16: 100%|██████████| 1563/1563 [15:19<00:00,  1.70it/s, loss=0.211]\nEpoch 13/16: 100%|██████████| 1563/1563 [15:19<00:00,  1.70it/s, loss=0.186]\nEpoch 14/16: 100%|██████████| 1563/1563 [15:20<00:00,  1.70it/s, loss=0.165]\nEpoch 15/16: 100%|██████████| 1563/1563 [15:21<00:00,  1.70it/s, loss=0.15] \nEpoch 16/16:  12%|█▏        | 187/1563 [01:50<13:35,  1.69it/s, loss=0.0929]","output_type":"stream"}]},{"cell_type":"code","source":"check_pruning_correctness_and_extent(model, compression_ratio)","metadata":{},"execution_count":null,"outputs":[]}]}